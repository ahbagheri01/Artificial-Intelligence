{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5_98105621.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bo8B7muFmAb"
      },
      "source": [
        "NAME : amirhossein bagheri \\\\\n",
        "STUDENT ID : 98105621"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucZuBUvu5xSV"
      },
      "source": [
        "import datetime\n",
        "import gym\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEFSFsl7fL63"
      },
      "source": [
        "class DQAgent:\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "        num_states = (env.observation_space.high - env.observation_space.low) * np.array([10, 100])\n",
        "        num_states = np.round(num_states, 0).astype(int) + 1\n",
        "        self.Q = np.zeros((num_states[0], num_states[1],env.action_space.n))\n",
        "        self.min = env.observation_space.low\n",
        "    def save(self, path,start,end):\n",
        "        np.save(path, self.Q)\n",
        "        file = open('training_time.txt', 'w')\n",
        "        file.write(\"start time is : \"+str(start)+\"\\n\"+\"end time is : \"+str(end)+\"\\n\"+\"total time is : \"+str(end - start))\n",
        "        file.close()\n",
        "    def load(self, path):\n",
        "        self.Q = np.load(path)\n",
        "    def test(self):\n",
        "      reward = 0\n",
        "      env = self.env\n",
        "      Q = self.Q\n",
        "      obs = env.reset()\n",
        "      done = False\n",
        "      while done != True:\n",
        "        state = self.get_state(obs)\n",
        "        action = np.argmax(Q[state[0], state[1]])\n",
        "        obs, r, done, info = env.step(action)\n",
        "        reward +=r\n",
        "        if done and obs[0] >= 0.5:\n",
        "          break\n",
        "      return reward\n",
        "    def get_state(self,obs):\n",
        "      return np.round((obs - self.min) * np.array([10, 100])).astype(int)\n",
        "    def train(self, learning, discount, epsilon, minE, episodes):\n",
        "        reduction = (epsilon - minE) / episodes\n",
        "        env = self.env\n",
        "        Q = self.Q\n",
        "        start = datetime.now()\n",
        "        for e in range(episodes) :\n",
        "            done = False\n",
        "            obs = env.reset()\n",
        "            current = self.get_state(obs)\n",
        "            while done != True:\n",
        "                i,j = current[0],current[1]\n",
        "                action = np.argmax(Q[i, j]) if np.random.random() > epsilon else np.random.randint(0, 3)\n",
        "                obs, reward, done, info = env.step(action)\n",
        "                next_state = self.get_state(obs)\n",
        "                i_p,j_p = next_state[0],next_state[1]\n",
        "                if done and obs[0] >= 0.5:\n",
        "                    Q[i,j, action] = reward\n",
        "                else:\n",
        "                    Q[i,j, action] += learning * (reward + discount * np.max(Q[i_p,j_p]) -Q[i,j, action])\n",
        "                current = next_state\n",
        "                epsilon -= reduction\n",
        "        env.close()\n",
        "        self.Q = Q\n",
        "        end = datetime.now()\n",
        "        self.save(\"policy\",start,end)\n",
        "        return start,end"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRIl0UmvcsBD",
        "outputId": "6b077036-9946-467a-aa81-7dd7b5924643"
      },
      "source": [
        "!pip install matplotlib\n",
        "!pip install gym"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFjyuzJP6q6e"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "حال به شرح تکه کد بالا می‌پردازیم:\n",
        "در قسمت constructorدو کار انجام می‌شود یکی آنکه مقادیر Q-table ها با مقادیر صفر پر می‌شوند که یک آرایه ۳ بعدی است که دو بعد اول آن معرف استیت و هر استیت یک آرایه به طول ۳ از مقادیر است که نشان دهنده مقدار value آن اکشن آن استیت است.\n",
        "همچنین مقادیر minimum سرعت و مختصات نیز ذخیره می‌شوند زیرا برای محاسبه استیت به آنها نیاز داریم.\n",
        "</div>\n",
        "\n",
        "<div dir=\"rtl\">\n",
        "بدست آوردن استیت:\n",
        "از‌آنجا که فضا پیوسته است برای محاسبه استیت نیاز به گسسته سازی آن داریم مقادیر بین بازه های سرعت و مختصات را رب حسب بیشترین دقت اعشاری اشان  , تقسیم بندی می‌کنیم به صورتی که بازه سرعت به بازه های 0.01تبدیل شده و بازه مختصات به بازه های 0.1 تقسیم می‌شود .\n",
        "</div>\n",
        "<div dir=\"rtl\">\n",
        "تابع get_state(): این تابع به سادگی اندیس استیت های مورد نظر را می دهید به صورتی که minimum را از سرعت و مختصات فعلی کم کرده و اعداد را در ۱۰ و۱۰۰ ضرب کرده و رند می‌کند.\n",
        "</div>\n",
        "<div dir=\"rtl\">\n",
        "توابع load  و save واضح اند.\n",
        "\n",
        "</div>\n",
        "<div dir=\"rtl\">\n",
        "تابع test محیط را یکبار ران می‌کند و برحسب جدول Q ها action مناسب را انتخاب می‌کند و ریوارد های هر action را جمع می‌زند و در آخر آنرا ریترن می‌کند.\n",
        "</div>\n",
        "<div dir=\"rtl\">\n",
        "تابع train(): این تابع ۵ آرگومان ورودی می‌گیرد که در ادامه به شرح و بررسی هر کدام مب‌پردازیم:\n",
        "\n",
        "</div>\n",
        "<div dir=\"rtl\">\n",
        "learning : همیان پارامتر learning rate در الگوریتم Q learning \n",
        "</div>\n",
        "<div dir=\"rtl\">\n",
        "discount : دراین مساله مقدار آن یک فرض می‌شود.\n",
        "\n",
        "</div>\n",
        "<div dir=\"rtl\">\n",
        "epsilon , minE : در روش مورد استفاده ما که روش epsilon decay یا epsilon greedy نام دارد مقدار اولیه epsilon مشخص می  کند که از ابتدا چقدر agent به exploreبپردازد هر چه مقدار آن بیشتر باشد بیشتر به اکسپلور پرداحته می‌شود.\n",
        "دقت کنید که با روند رو به جلو الگوریتم این مقدار کاهش می‌یابد  تا در نهایت با کانورج دیگر الگوریتم اکسپلور انجام ندهد.\n",
        ". مقدار minE نیز کران پایین مقدار اپسیلون است.\n",
        "</div>\n",
        "<div dir=\"rtl\">\n",
        "episodes  : تعداد اپیزود های را مشخص می‌کند.\n",
        "\n",
        "</div>\n",
        "<div dir=\"rtl\">\n",
        "فرایند train :\n",
        "</div>\n",
        "</div>\n",
        "<div dir=\"rtl\">\n",
        "در ابتدا چون اپسیلون زیاد است agent می تواند اکسپلور انجام دهد. و پس از مدتی مقدار اپسیلون کاهش می‌یابد و agent بر حسب مقادیر Q ها تصمیم می‌گیرد(به احتمال زیاد). دقت کنید که در هر مرحله به صورت on policy مقادیر Q اپدیت می‌شود.\n",
        "</div>\n",
        "<div dir=\"rtl\">\n",
        "پارامتر های learning , episods بر اساس چندین بار آزمایش مقادیر مطلوبشان بدست آمده است.\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPkAjsCa0KpC"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "همانطور که مشاهده می‌کنید با ۵۰۰۰۰ اپیزود و مدت ترین ۱۱ دقیقه مدل را ترین کرده و نتایج را در قالب یک فایل به اسم policy ذخیره می‌کنیم.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjI-btFNjpc4",
        "outputId": "f08747e0-78d2-458a-d86d-10841fc4a7db"
      },
      "source": [
        "env = gym.make(\"MountainCar-v0\")\n",
        "agent = DQAgent(env)\n",
        "start,end = agent.train(learning = 0.25, discount = 1, epsilon = 1, minE = 0, episodes = 50000  )\n",
        "print(\"traning time : \",end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "traning time :  0:09:29.006052\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xlKQ6sG1GuA"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "در طی ۱۱ دقیقه مدل ترین شده و مقادیر qاماده استفاده برای بخش تست هستند.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmWfBfz91K6G"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "در قسمت زیر مدل را ۱۰۰۰۰ بار تست می‌کنیم و نتایج تست هارا در یک آرایه ذخیره می‌کنیم. و آنرا در قالب یک npy ذخیره می‌کنیم.\n",
        "دقت کنید از آنجا که q های نهایی را در قسمت قبی ذخیره کرده ایم در این قسمت یک مدل جدید می‌سازیم و مقادیر قسمت قبل را در آن لود می‌کنیم.\n",
        "(اینکار به جهت سهولت برای اجرای سل ها انجام شده است.)\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEfTw8cVfQO8"
      },
      "source": [
        "env = gym.make(\"MountainCar-v0\")\n",
        "agent = DQAgent(env)\n",
        "agent.load(\"policy.npy\")\n",
        "rewards = []\n",
        "for i in range(10000):\n",
        "  rewards.append(agent.test())\n",
        "np.save(\"reward_list_results\", np.array(rewards))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dmtdgo90x61"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "در قسمت زیر به بررسی مقادیر بدست آمده از ۱۰۰۰ تست می‌پردازیم.\n",
        "اینکه چه تعداد از انها کمتر از -150 شده اند و چه تعداد از آنها کمتر از -140شده اند.\n",
        "میانگین ریوارد های چه عددیست و standard deviationاشان  همچنین با استفاده از histogram مقادیر ریوارد های بدست آمده را نشان می‌دهیم.\n",
        " \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "T9dJBdcOfVhh",
        "outputId": "6504cb96-907e-465f-de05-45aeb4be0dcb"
      },
      "source": [
        "array = np.load(\"reward_list_results.npy\")\n",
        "file = open('test_results.txt', 'w')\n",
        "size = len(array)\n",
        "s =sum(array >= -140)\n",
        "res = \"number of more than -140 from \"+str(len(array))+\" test : \"+str(s)+\" \"+str(100*s/size)+\"%\\n\"\n",
        "s =sum(array >= -150)\n",
        "res+=\"number of more than -150 from \"+str(len(array))+\" test :  \"+str(s)+\" \"+str(100*s/size)+\"%\\n\"\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(18.5, 10.5)\n",
        "plt.hist(array, bins=40, density=True, alpha=0.6, color='b')\n",
        "plt.savefig(\"result_plot.png\")\n",
        "res+=\"rewards mean is : \"+str(np.mean(rewards))+\"\\n\"\n",
        "res+=\"rewards std is : \"+str(np.std(rewards))\n",
        "file.write(res)\n",
        "file.close()\n",
        "print(res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of more than -140 from 10000 test : 9786 97.86%\n",
            "number of more than -150 from 10000 test :  10000 100.0%\n",
            "rewards mean is : -137.3932\n",
            "rewards std is : 1.9314745041030184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1332x756 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}